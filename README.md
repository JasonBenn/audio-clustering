### Unknowns

#### What is the actual architecture of the net? What objective function ensures embeddings are far away from each other if they're different instruments, and close together if they're the same instrument?

#### How do I label my data?
* Is it sliding windows of combined audio, where the dominant audio is the label? That wouldn't work for music, because they're all on top of each other. Would it work for spectograms? Maybe.

#### What data is available?
* CMMSD: monophonic music with ground truth.

#### How do I view my data as a spectogram? What Python library can do this?

#### How do I combine different audio tracks into one?

#### How do I turn the volume down for one embedding and combine it back into audio?
